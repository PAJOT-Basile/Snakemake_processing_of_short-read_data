######################## Libraries ###############################
import os
import pandas as pd
import numpy as np

######################## Import custom functions ###############################
from snakemake_functions import *

######################## Import values from the configuration file  ###############################
raw_data_path = config["raw_data_path"]
outputs_files = config["outputs_files"]
final_output = config["final_output"]
input_reference_genome = config["input_reference_genome"]
temp_path = config["temp_path"]

######################## Get the sample names  ###############################
# First, we import the patterns to keep and to exclude from the sample names from the config file
patterns_in = config["patterns_in"]
patterns_out = config["patterns_out"]

# We use the function to get the sample names from the input file
# (The first commented line is to test on just two samples (the first and the last one of the list) to test the snakemake)
#SAMPLES = [list_samples(raw_data_path, patterns_in, patterns_out)[i] for i in (0, -1)]
SAMPLES = list_samples(raw_data_path, patterns_in, patterns_out)
# The print of the samples is not necessary for the snakemake to work, but it is useful to be sure that all the samples you
# wish to work on are here
print(SAMPLES)

######################## Get the name of the reference genome  ###############################
NAME_GENOME = get_reference_genome_name(input_reference_genome)   
reference_genome = final_output + "Reference/" + NAME_GENOME

######################## Index reference genome  ###############################
index_ref_genome(input_reference_genome, reference_genome)
os.wait()

######################## Cut chromosomes  ###############################
bin_size = config["bin_size"]
REGIONS = get_chromosome_positions_breaks(reference_genome, bin_size=bin_size)

######################## Global variables  ###############################
READS = ["R1", "R2"]
STEPS = ["Fastp", "Raw"]

######################## Memory allocation functions  ###############################
######################## Get the input file size  ###############################
def get_input_file_size(wildcards, input):
    return(input.size_mb)

######################## FastP  ###############################
def get_mem_mb_fastp(wildcards, input):
    input_file_size = get_input_file_size(wildcards, input)
    return(input_file_size * 0.2 + 5000)

######################## FastQC  ###############################
def get_mem_mb_fastqc(wildcards, input):
    input_file_size = get_input_file_size(wildcards, input)
    return(0.002 * input_file_size + 2640)

######################## MultiQC  ###############################
def get_mem_mb_multiqc(wildcards, input):
    nb_individuals = len(input.zip)/2
    return(nb_individuals * 27 + 765)

######################## BWA MEM  ###############################
def get_mem_mb_bwa(wildcards, input):
    input_file_size = get_input_file_size(wildcards, input)
    return(0.2 * input_file_size + 10000)

######################## Samtools Collate  ###############################
def get_mem_mb_collate(wildcards, input):
    input_file_size = get_input_file_size(wildcards, input)
    return(0.4 * input_file_size + 7000)

######################## Samtools fixmate  ###############################
def get_mem_mb_fixmate(wildcards, input):
    input_file_size = get_input_file_size(wildcards, input)
    return(0.01 * input_file_size + 4000)

######################## Samtools sort  ###############################
def get_mem_mb_sort(wildcards, input):
    input_file_size = get_input_file_size(wildcards, input)
    return(0.02 * input_file_size + 15000)

######################## Samtools markdup  ###############################
def get_mem_mb_markdup(wildcards, input):
    input_file_size = get_input_file_size(wildcards, input)
    return(0.001 * input_file_size + 1750)










######################## RULES  ###############################
######################## rule all  ###############################
# Allows to check for input and outputs
rule all:
    input:
        # Rule N01_Create_Arborescence
        ".mkdir.done",

        # Rule N02_FastP
        expand(final_output + "Fastp/html/{sample}.html", sample=SAMPLES),
        expand(final_output + "Fastp/json/{sample}.json", sample=SAMPLES),

        # Rule N04_MultiQC
        expand(final_output + "MultiQC/Quality_results_on_{step}.html", step=STEPS),

        # Rule N05_Move_Fastqc_out
        expand(final_output + "Fastqc_out/{step}/{sample}.{read}_fastqc.html", sample=SAMPLES, read=READS, step=STEPS),

        # Rule N10_Mark_duplicates
        expand(final_output + "Marked_duplicates/{sample}.cram", sample=SAMPLES),

        # Rule N11_Index_Flagstate
        expand(final_output + "Marked_duplicates/{sample}.cram.crai", sample=SAMPLES),
        expand(final_output + "Flagstat_reports/{sample}.flagstat", sample=SAMPLES),

        # Rule N13_Compile_CRAM_files
        expand(final_output + "Full_VCF/VCF_File_{region}.vcf.gz", region=REGIONS),

        # Rule N14_Count_SNPs_2
        final_output + "Stats_VCF/Number_SNPs_per_region.csv",

        # Rule N15_Concatenate_VCFs
        #final_output + "Full_VCF/Variant_calling_with_ref_genome.vcf.gz"

        # Rule N17_VCF_Concat_after_filtering
        final_output + "Filtered_VCF/Removed_indels_and_multiallelic_sites.vcf.gz",

        # Rule N19_Concat_Stats
        final_output + "Stats/DP/vcfstats.DP.txt",
        final_output + "Stats/MQ/vcfstats.MQ.txt",
        final_output + "Stats/QUAL/vcfstats.QUAL.txt",
        final_output + "Stats/SP/vcfstats.SP.txt",
        final_output + "Stats/AF/vcfstats.AF.txt",

        # Rule N21_Concatenate_Missing_data
        final_output + "Missing_data/Full_data.lmiss"


######################## Create arborescence  ###############################
rule N01_Create_Arborescence:
    input:
        "input_file.txt"
    output:
        directory(".mkdir.done")
    params:
        # Rule N02_FastP
        outputs_files + "Fastp/",
        final_output + "Fastp/json/",
        final_output + "Fastp/html/",

        # Rule N03_FastQC
        final_output + "Fastqc_out/Raw/",
        outputs_files + "Fastqc_out/Raw/",
        final_output + "Fastqc_out/Fastp/",
        outputs_files + "Fastqc_out/Fastp/",

        # Rule N04_MultiQC
        final_output + "MultiQC/",

        # Rule N06_Map_ref_genome
        outputs_files + "Mapped_genomes/",

        # Rule N07_Collate_CRAM
        outputs_files + "Sorted_genomes/",

        # Rule N10_Mark_duplicates
        final_output + "Marked_duplicates/",

        # Rule N11_Index_Flagstate
        final_output + "Flagstat_reports/",

        # Rule N12_Create_list_CRAM_files
        outputs_files + "Concatenation/",

        # Rule N13_Compile_CRAM_files
        outputs_files + "VCF_files/",

        # Rule N14_Count_SNPs       
        final_output + "Stats_VCF/",
        outputs_files + "Stats_VCF",

        # Rule N15_Concatenate_VCFs
        final_output + "Full_VCF/",
        
        # Rule N16_Remove_Indels
        final_output + "Removed_indels/",

        # Rule N17_VCF_Concat_after_filtering
        final_output + "Filtered_VCF/",

        # Rule N18_Stats_Filtering
        outputs_files + "Stats/DP/",
        outputs_files + "Stats/MQ/",
        outputs_files + "Stats/QUAL/",
        outputs_files + "Stats/SP/",
        outputs_files + "Stats/AF/",

        # Rule N19_Concat_Stats
        final_output + "Stats/DP/",
        final_output + "Stats/MQ/",
        final_output + "Stats/QUAL/",
        final_output + "Stats/SP/",
        final_output + "Stats/AF/",

        # Rule N20_Missing_data
        outputs_files + "Missing_data/",

        # Rule N21_Concatenate_Missing_data
        final_output + "Missing_data/",

        # Temporary files
        temp_path,

    shell:
        """
            mkdir -p {output:q} {params:q}
        """

######################## Run FastP on raw files  ###############################
rule N02_FastP:
    input:
        fake = rules.N01_Create_Arborescence.output,
        raw_R1 = raw_data_path + "{sample}.R1.fastq.gz",
        raw_R2 = raw_data_path + "{sample}.R2.fastq.gz"
    output:
        fastp_R1 = temp(outputs_files + "Fastp/{sample}.R1.fastq.gz"),
        fastp_R2 = temp(outputs_files + "Fastp/{sample}.R2.fastq.gz"),
        html = final_output + "Fastp/html/{sample}.html",
        json = final_output + "Fastp/json/{sample}.json"
    threads: 4
    resources:
        mem_mb = get_mem_mb_fastp
    message:
        "Processing {wildcards.sample} in FastP"
    shell:
        """
            fastp -i {input.raw_R1:q} -I {input.raw_R2:q} -o {output.fastp_R1:q} -O {output.fastp_R2:q} --thread {threads} -g -c -y 30 --html {output.html:q} --json {output.json:q}
        """


######################## Function to create a rule for the fastqc on different steps  ###############################
def rule_fastqc(step, raw_data_path, outputs_files):
    rule:
        name: f"N03_FastQC_on_{step}"
        input:
            real = input_fastqc(step, raw_data_path, outputs_files),
            fake = rules.N01_Create_Arborescence.output
        output:
            zip_out = temp(outputs_files + f"Fastqc_out/{step}/{{sample}}.{{read}}_fastqc.zip"),
            html_out = outputs_files + f"Fastqc_out/{step}/{{sample}}.{{read}}_fastqc.html"
        message:
            f"{step} data of sample {{wildcards.sample}}.{{wildcards.read}} in FastQC"
        resources:
            mem_mb = get_mem_mb_fastqc
        shell:
            f"""
                fastqc {{input.real:q}} -o {{config[outputs_files]:q}}Fastqc_out/{step}/
            """


######################## Function to create a rule for the multiqc on different steps  ###############################
def rule_multiqc(step, outputs_files, final_output):
    rule:
        name: f"N04_MultiQC_on_{step}"
        input:
            zip = expand(outputs_files + f"Fastqc_out/{step}/{{sample}}.{{read}}_fastqc.zip", sample=SAMPLES, read=READS),
            html = expand(outputs_files + f"Fastqc_out/{step}/{{sample}}.{{read}}_fastqc.html", sample=SAMPLES, read=READS)
        output:
            final_output + f"MultiQC/Quality_results_on_{step}.html"
        params:
            INDIR = outputs_files + f"Fastqc_out/{step}/",
            OUTDIR = final_output + "MultiQC/",
            OUTNAME = final_output + f"MultiQC/Quality_results_on_{step}"
        resources:
            mem_mb = get_mem_mb_multiqc
        message:
            f"Quality control with MultiQC on {step} data"
        shell:
            """
                multiqc {params.INDIR:q} -o {params.OUTDIR:q} -n {params.OUTNAME:q} --force
            """


######################## Function to create a rule for the multiqc on different steps  ###############################
def move_output(step, outputs_files, final_output):
    rule:
        name: f"N05_Move_Fastqc_out_after_{step}"
        input:
            final_output + f"MultiQC/Quality_results_on_{step}.html"
        output:
            expand(final_output + f"Fastqc_out/{step}/{{sample}}.{{read}}_fastqc.html", sample=SAMPLES, read=READS)
        params:
            inputs = expand(outputs_files + f"Fastqc_out/{step}/{{sample}}.{{read}}_fastqc.html", sample=SAMPLES, read=READS),
            outdir = final_output + f"Fastqc_out/{step}/",
        shell:
            """
                mv {params.inputs:q} {params.outdir:q}
            """


######################## Run the created functions on the raw and trimmed data  ###############################
for counter, step in enumerate(STEPS):
    rule_fastqc(step, raw_data_path, outputs_files)
    rule_multiqc(step, outputs_files, final_output)
    move_output(step, outputs_files, final_output)


######################## Map on the reference genome  ###############################
rule N06_Map_ref_genome:
    input:
        trimmed_R1 = rules.N02_FastP.output.fastp_R1,
        trimmed_R2 = rules.N02_FastP.output.fastp_R2,
        reference_genome_indexed = reference_genome + ".amb",
        ref_genome = reference_genome
    output:
        temp(outputs_files + "Mapped_genomes/{sample}.cram")
    threads: 10
    resources:
        partition="long",
        mem_mb = get_mem_mb_bwa
    message:
        "Mapping {wildcards.sample} on {NAME_GENOME}"
    shell:
        r"""
            mkdir -p {config[temp_path]}
            export TMPDIR="{config[temp_path]}" TMP="{config[temp_path]}" TEMP="{config[temp_path]}"
            bwa mem -M -t {threads} -R '@RG\tID:1\tSM:{wildcards.sample}\tPL:ILLUMINA\tLB:lib\tPU:transect' {input.ref_genome:q} {input.trimmed_R1:q} {input.trimmed_R2:q} | samtools view -C -T {input.ref_genome:q} > {output:q}
        """


######################## Collate the CRAM files  ###############################
rule N07_Collate_CRAM:
    input:
        rules.N06_Map_ref_genome.output
    output:
        temp(outputs_files + "Sorted_genomes/{sample}.0.cram")
    threads: 10
    resources:
        mem_mb = get_mem_mb_collate
    message:
        "Sorting {wildcards.sample}"
    shell:
        """
            samtools collate -@ {threads} {input:q}  -o {output:q} {config[temp_path]} --output-fmt CRAM 
        """


######################## Fixmate the CRAM files  ###############################
rule N08_Fixmate_CRAM:
    input:
        rules.N07_Collate_CRAM.output
    output:
        temp(outputs_files + "Sorted_genomes/{sample}.1.cram")
    threads: 10
    resources:
        mem_mb = get_mem_mb_fixmate
    message:
        "Sorting {wildcards.sample}"
    shell:
        """
            mkdir -p {config[temp_path]}
            export TMPDIR="{config[temp_path]}" TMP="{config[temp_path]}" TEMP="{config[temp_path]}"
            samtools fixmate -@ {threads} -m {input:q} -O CRAM {output:q}
        """


######################## Sort the CRAM files  ###############################
rule N09_Sort_CRAM:
    input:
        rules.N08_Fixmate_CRAM.output
    output:
        temp(outputs_files + "Sorted_genomes/{sample}.cram")
    threads: 10
    resources:
        mem_mb = get_mem_mb_sort
    message:
        "Sorting {wildcards.sample}"
    shell:
        """
            samtools sort -@ {threads} {input:q} -O CRAM -o {output:q} -T {config[temp_path]}
        """


######################## Mark the duplicates  ###############################
rule N10_Mark_duplicates:
    input:
        rules.N09_Sort_CRAM.output
    output:
        final_output + "Marked_duplicates/{sample}.cram"
    threads: 10
    resources:
        mem_mb = get_mem_mb_markdup
    message:
        "Marking duplicates for {wildcards.sample}"
    shell:
        """
            samtools markdup -@ {threads} -d 2500 {input:q} {output:q} -T {config[temp_path]} -O CRAM
        """


######################## Index the CRAM file and do some stats  ###############################
rule N11_Index_Flagstate:
    input:
        rules.N10_Mark_duplicates.output
    output:
        index = final_output + "Marked_duplicates/{sample}.cram.crai",
        flagstat = final_output + "Flagstat_reports/{sample}.flagstat"
    threads: 1
    message:
        "Indexing and making stats on {wildcards.sample}"
    shell:
        """
            samtools index -@ {threads} -b {input:q} > {output.index:q} 
            samtools flagstat -@ {threads} {input:q} > {output.flagstat:q}
        """


######################## Make a list of the CRAM files  ###############################
rule N12_Create_list_CRAM_files:
    input:
        real = expand(final_output + "Marked_duplicates/{sample}.cram", sample=SAMPLES),
        fake = expand(final_output + "Marked_duplicates/{sample}.cram.crai", sample=SAMPLES)
    output:
        temp(outputs_files + "Concatenation/List_cram_files.txt")
    shell:
        """
            LIST_DIR={config[final_output]}Marked_duplicates/*
            ls -d $LIST_DIR | grep -v ".crai" > {output:q}
        """


######################## Variant Calling  ###############################
rule N13_Compile_CRAM_files:
    input:
        ref_genome = reference_genome,
        list_cram_files = rules.N12_Create_list_CRAM_files.output,
        fake = expand(rules.N11_Index_Flagstate.output.index, sample=SAMPLES)
    output:
        final_output + "Full_VCF/VCF_File_{region}.vcf.gz"
    threads: 10
    resources:
        mem_mb = config["mem_mpileup"]
    params:
        region = expand("{region}", region=REGIONS)
    message:
        "VCF file preparation in region: {wildcards.region}"
    shell:
        """
            mkdir -p {config[temp_path]}
            export TMPDIR="{config[temp_path]}" TMP="{config[temp_path]}" TEMP="{config[temp_path]}"
            bcftools mpileup --threads {threads} -a FORMAT/AD,FORMAT/DP,FORMAT/SP,INFO/AD --fasta-ref {input.ref_genome:q} -b {input.list_cram_files:q} --regions {wildcards.region} | bcftools call --threads {threads} -m -Oz -o {output:q}
        """


######################## Count the number of SNPs in the file part 1  ###############################
rule N14_Count_SNPs:
    input:
        rules.N13_Compile_CRAM_files.output
    output:
        temp(outputs_files + "Stats_VCF/Number_SNPs_{region}.csv")
    shell:
        """
            NSNPs=$(echo "$(zcat {input:q} | grep -v '#' | wc -l) + 1" | bc)
            echo "{wildcards.region};$(echo "$NSNPs -1 " | bc)" >> {output:q}
        """


######################## Count the number of SNPs in the file part 2  ###############################
rule N14_Count_SNPs_2:
    input:
        rules.N14_Count_SNPs.output
    output:
        final_output + "Stats_VCF/Number_SNPs_per_region.csv",
    shell:
        """
            cat {input:q} >> {output:q}
        """


######################## Concatenate the VCF files  ###############################
#rule N15_Concatenate_VCFs:
#    input:
#        expand(outputs_files + "VCF_files/VCF_File_{regions}.vcf.gz", regions=REGIONS)
#    output:
#        temp_out = temp(final_output + "Full_VCF/Variant_calling_with_ref_genome.vcf"),
#        real_out = final_output + "Full_VCF/Variant_calling_with_ref_genome.vcf.gz"
#    message:
#        "Concatenating VCF files"
#    resources:
#        partition = "long"
#    shell:
#        """
#            zcat {input[0]:q} | grep "#" > {output.temp_out:q}
#            zcat {input:q} | grep -v "#" >> {output.temp_out:q}
#            tar -czf {output.real_out:q} {output.temp_out:q}
#        """


######################## Remove Indels and multiallelic sites  ###############################
rule N16_Remove_Indels:
    input:
        rules.N13_Compile_CRAM_files.output
    output:
        temp(outputs_files + "Removed_indels/SNP_only_{region}.vcf.gz")
    threads: 10
    message:
        "Removing Indels and multiallelic sites for {wildcards.region}"
    shell:
        """
            mkdir -p {config[temp_path]}
            export TMPDIR="{config[temp_path]}" TMP="{config[temp_path]}" TEMP="{config[temp_path]}"
            bcftools filter -Ou --threads {threads} -g 5:indel,other {input:q} | bcftools view -Oz --threads {threads} -M 2 -m 2 -v snps > {output:q}
        """


######################## Concatenating filtered VCFs  ###############################
rule N17_VCF_Concat_after_filtering:
    input:
        expand(rules.N16_Remove_Indels.output, region=REGIONS)
    output:
        temp_out = temp(outputs_files + "Filtered_VCF/Removed_indels_and_multiallelic_sites.vcf"),
        real_out = final_output + "Filtered_VCF/Removed_indels_and_multiallelic_sites.vcf.gz"
    message:
        "Concatenating filtered VCFs"
    shell:
        """
            zcat {input[0]:q} | grep "#" > {output.temp_out:q}
            zcat {input:q} | grep -v "#" >> {output.temp_out:q}
            tar -czf {output.real_out:q} {output.temp_out:q}
        """


######################## Stats  ###############################
rule N18_Stats_Filtering:
    input:
        rules.N16_Remove_Indels.output,
    output:
        tot_depth = temp(outputs_files + "Stats/DP/depth_stats_{region}.txt"),
        map_qual = temp(outputs_files + "Stats/MQ/map_q_{region}.txt"),
        site_qual = temp(outputs_files + "Stats/QUAL/site_qual_{region}.txt"),
        phred = temp(outputs_files + "Stats/SP/phred_qual_{region}.txt"),
        allel_freq = temp(outputs_files + "Stats/AF/allel_freq_{region}.txt"),
    message:
        "Doing stats after removing indels on {wildcards.region}"
    shell:
        r"""
            mkdir -p {config[temp_path]}
            export TMPDIR="{config[temp_path]}" TMP="{config[temp_path]}" TEMP="{config[temp_path]}"

            # Total depth read
            bcftools query -f "%CHROM\t%POS\t%DP\t]\n" {input:q} > {output.tot_depth:q}

            # Map quality per site
            bcftools query -f "%CHROM\t%POS\t%MQ\n" {input:q} > {output.map_qual:q}
            
            # Call quality per site
            bcftools query -f "%CHROM\t%POS\t%QUAL\n" {input:q} > {output.site_qual:q}

            # Strand-bias P-value (Phread score)
            bcftools query -f "%CHROM\t%POS\t[%SP\t]\n" {input:q} | awk 'BEGIN{{OFS="\t"}}{{sum=0; for (i=3; i<=NF; i++) sum+=$i; sum/=NF; print $1,$2,sum}}' > {output.phred:q}

            # Depth per sample
            bcftools +fill-tags {input:q} -- -t AF | bcftools query -f "%CHROM\t%POS\t%AF\n" > {output.allel_freq:q}
        """


######################## Concat Stats  ###############################
rule N19_Concat_Stats:
    input:
        tot_depth = expand(outputs_files + "Stats/DP/depth_stats_{region}.txt", region=REGIONS),
        map_qual = expand(outputs_files + "Stats/MQ/map_q_{region}.txt", region=REGIONS),
        site_qual = expand(outputs_files + "Stats/QUAL/site_qual_{region}.txt", region=REGIONS),
        phred = expand(outputs_files + "Stats/SP/phred_qual_{region}.txt", region=REGIONS),
        allel_freq = expand(outputs_files + "Stats/AF/allel_freq_{region}.txt", region=REGIONS),
    output:
        tot_depth = final_output + "Stats/DP/vcfstats.DP.txt", 
        map_qual = final_output + "Stats/MQ/vcfstats.MQ.txt", 
        site_qual = final_output + "Stats/QUAL/vcfstats.QUAL.txt", 
        phred = final_output + "Stats/SP/vcfstats.SP.txt", 
        allel_freq = final_output + "Stats/AF/vcfstats.AF.txt"
    message:
        "Concatenating Stats"
    shell:
        """
            cat {input.tot_depth:q} > {output.tot_depth:q}
            cat {input.map_qual:q} > {output.map_qual:q}
            cat {input.site_qual:q} > {output.site_qual:q}
            cat {input.phred:q} > {output.phred:q}
            cat {input.allel_freq:q} > {output.allel_freq:q}
        """


######################## Get missing data per region  ###############################
rule N20_Missing_data:
    input:
        real = rules.N16_Remove_Indels.output,
        fake = rules.N01_Create_Arborescence.output
    output:
        expected = temp(outputs_files + "Missing_data/{region}.lmiss")
    params:
        prefix = outputs_files + "Missing_data/{region}"
    message:
        "Getting missing data on region: {wildcards.region}"
    shell:
        """
            vcftools --gzvcf {input.real:q} --out {params.prefix:q} --missing-site
        """


######################## Get missing data per region  ###############################
rule N21_Concatenate_Missing_data:
    input:
        expand(rules.N20_Missing_data.output.expected, region=REGIONS)
    output:
        final_output + "Missing_data/Full_data.lmiss"
    message:
        "Concatenating Missing_data"
    shell:
        """
            cat {input:q} > {output:q}
        """
