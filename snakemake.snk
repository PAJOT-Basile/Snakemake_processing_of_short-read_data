######################## Libraries ###############################
import os
import pandas as pd
import numpy as np

######################## Import custom functions ###############################
from snakemake_functions import *

######################## Import values from the configuration file  ###############################
raw_data_path = config["raw_data_path"]
outputs_files = config["outputs_files"]
final_output = config["final_output"]
input_reference_genome = config["input_reference_genome"]
temp_path = config["temp_path"]

######################## Get the sample names  ###############################
# First, we import the patterns to keep and to exclude from the sample names from the config file
patterns_in = config["patterns_in"]
patterns_out = config["patterns_out"]

# We use the function to get the sample names from the input file
# (The first commented line is to test on just two samples (the first and the last one of the list) to test the snakemake)
#SAMPLES = [list_samples(raw_data_path, patterns_in, patterns_out)[i] for i in (0, -1)]
SAMPLES = list_samples(raw_data_path, patterns_in, patterns_out)
# The print of the samples is not necessary for the snakemake to work, but it is useful to be sure that all the samples you
# wish to work on are here
print(SAMPLES)

######################## Get the name of the reference genome  ###############################
NAME_GENOME = get_reference_genome_name(input_reference_genome)   
reference_genome = final_output + "Reference/" + NAME_GENOME

######################## Index reference genome  ###############################
index_ref_genome(input_reference_genome, reference_genome)
os.wait()

######################## Cut chromosomes  ###############################
bin_size = config["bin_size"]
REGIONS = get_chromosome_positions_breaks(reference_genome, bin_size=bin_size)

######################## Global variables  ###############################
READS = ["R1", "R2"]
STEPS = ["Fastp", "Raw"]
LATE_STEPS = ["Full_VCF", "Mac_data", "Removed_indels", "Missing_data"]

######################## Memory allocation functions  ###############################
######################## Get the input file size  ###############################
def get_input_file_size(wildcards, input):
    return(input.size_mb)

######################## FastP  ###############################
def get_mem_mb_fastp(wildcards, input):
    input_file_size = get_input_file_size(wildcards, input)
    return(input_file_size * 0.2 + 5000)

######################## FastQC  ###############################
def get_mem_mb_fastqc(wildcards, input):
    input_file_size = get_input_file_size(wildcards, input)
    return(0.002 * input_file_size + 2640)

######################## MultiQC  ###############################
def get_mem_mb_multiqc(wildcards, input):
    nb_individuals = len(input.zip)/2
    return(nb_individuals * 27 + 765)

######################## BWA MEM  ###############################
def get_mem_mb_bwa(wildcards, input):
    input_file_size = get_input_file_size(wildcards, input)
    return(0.2 * input_file_size + 10000)

######################## Samtools Collate  ###############################
def get_mem_mb_collate(wildcards, input):
    input_file_size = get_input_file_size(wildcards, input)
    return(0.4 * input_file_size + 7000)

######################## Samtools fixmate  ###############################
def get_mem_mb_fixmate(wildcards, input):
    input_file_size = get_input_file_size(wildcards, input)
    return(0.01 * input_file_size + 4000)

######################## Samtools sort  ###############################
def get_mem_mb_sort(wildcards, input):
    input_file_size = get_input_file_size(wildcards, input)
    return(0.02 * input_file_size + 15000)

######################## Samtools markdup  ###############################
def get_mem_mb_markdup(wildcards, input):
    input_file_size = get_input_file_size(wildcards, input)
    return(0.001 * input_file_size + 1750)










######################## RULES  ###############################
######################## rule all  ###############################
# Allows to check for input and outputs
rule all:
    input:
        # Rule N01_Create_Arborescence
        ".mkdir.done",

        # Rule N02_FastP
        expand(final_output + "Fastp/html/{sample}.html", sample=SAMPLES),
        expand(final_output + "Fastp/json/{sample}.json", sample=SAMPLES),

        # Rule N04_MultiQC
        expand(final_output + "MultiQC/Quality_results_on_{step}.html", step=STEPS),

        # Rule N05_Move_Fastqc_out
        expand(final_output + "Fastqc_out/{step}/{sample}.{read}_fastqc.html", sample=SAMPLES, read=READS, step=STEPS),

        # Rule N10_Mark_duplicates
        expand(final_output + "Marked_duplicates/{sample}.cram", sample=SAMPLES),

        # Rule N11_Index_Flagstate
        expand(final_output + "Marked_duplicates/{sample}.cram.crai", sample=SAMPLES),
        expand(final_output + "Flagstat_reports/{sample}.flagstat", sample=SAMPLES),

        # Rule N13_Compile_CRAM_files
        expand(final_output + "Full_VCF/VCF_File_{region}.vcf.gz", region=REGIONS),

        # Position Count_SNPs
        expand(final_output + "{step}/Position_count.csv", step=LATE_STEPS),

        # Concatenate vcf files
        expand(final_output + "{step}/VCF_File.vcf.gz", step=["Mac_data", "Removed_indels", "Missing_data"]),
        
        # Concatenate the stats            
        expand(final_output + "{step}/Stats/vcfstats.QUAL.txt", step=LATE_STEPS),
        expand(final_output + "{step}/Stats/vcfstats.SP.txt", step=LATE_STEPS),
        expand(final_output + "{step}/Stats/vcfstats.AF.txt", step=LATE_STEPS),
        expand(final_output + "{step}/Stats/vcfstats.DP.txt", step=LATE_STEPS),
        expand(final_output + "{step}/Stats/vcfstats.lmiss", step=LATE_STEPS),

        # Plot the quality graphs
        expand(final_output + "{step}/Quality_distribution.png", step=LATE_STEPS)


######################## Create arborescence  ###############################
rule N01_Create_Arborescence:
    input:
        "input_file.txt"
    output:
        directory(".mkdir.done")
    params:
        # Rule N02_FastP
        outputs_files + "Fastp/",
        final_output + "Fastp/json/",
        final_output + "Fastp/html/",

        # Rule N03_FastQC
        final_output + "Fastqc_out/Raw/",
        outputs_files + "Fastqc_out/Raw/",
        final_output + "Fastqc_out/Fastp/",
        outputs_files + "Fastqc_out/Fastp/",

        # Rule N04_MultiQC
        final_output + "MultiQC/",

        # Rule N06_Map_ref_genome
        outputs_files + "Mapped_genomes/",

        # Rule N07_Collate_CRAM
        outputs_files + "Sorted_genomes/",

        # Rule N10_Mark_duplicates
        final_output + "Marked_duplicates/",

        # Rule N11_Index_Flagstate
        final_output + "Flagstat_reports/",

        # Rule N12_Create_list_CRAM_files
        outputs_files + "Concatenation/",

        # Rule N13_Compile_CRAM_files
        final_output + "VCF_files/",

        # N14_MAC
        outputs_files + "Mac_data",

        # N15_Remove_Indels
        outputs_files + "Removed_indels/",

        # N16_Filter_missing_rate
        outputs_files + "Missing_data/",

        # Position count and statistics
        outputs_files + "Full_VCF/Stats/",
        outputs_files + "Mac_data/Stats/",
        outputs_files + "Removed_indels/Stats/",
        outputs_files + "Missing_data/Stats/",

        # Concat position count, concat vcf files, concat stats and plot the graphs
        final_output + "Full_VCF/Stats/",
        final_output + "Mac_data/Stats/",
        final_output + "Removed_indels/Stats/",
        final_output + "Missing_data/Stats/",


        # Temporary files
        temp_path,

    shell:
        """
            mkdir -p {output:q} {params:q}
        """


######################## Run FastP on raw files  ###############################
rule N02_FastP:
    input:
        fake = rules.N01_Create_Arborescence.output,
        raw_R1 = raw_data_path + "{sample}.R1.fastq.gz",
        raw_R2 = raw_data_path + "{sample}.R2.fastq.gz"
    output:
        fastp_R1 = temp(outputs_files + "Fastp/{sample}.R1.fastq.gz"),
        fastp_R2 = temp(outputs_files + "Fastp/{sample}.R2.fastq.gz"),
        html = final_output + "Fastp/html/{sample}.html",
        json = final_output + "Fastp/json/{sample}.json"
    threads: 4
    resources:
        mem_mb = get_mem_mb_fastp
    message:
        "Processing {wildcards.sample} in FastP"
    shell:
        """
            fastp -i {input.raw_R1:q} -I {input.raw_R2:q} -o {output.fastp_R1:q} -O {output.fastp_R2:q} --thread {threads} -g -c -y 30 --html {output.html:q} --json {output.json:q}
        """


######################## Function to create a rule for the fastqc on different steps  ###############################
def rule_fastqc(step, raw_data_path, outputs_files):
    rule:
        name: f"N03_FastQC_on_{step}"
        input:
            real = input_fastqc(step, raw_data_path, outputs_files),
            fake = rules.N01_Create_Arborescence.output
        output:
            zip_out = temp(outputs_files + f"Fastqc_out/{step}/{{sample}}.{{read}}_fastqc.zip"),
            html_out = outputs_files + f"Fastqc_out/{step}/{{sample}}.{{read}}_fastqc.html"
        message:
            f"{step} data of sample {{wildcards.sample}}.{{wildcards.read}} in FastQC"
        resources:
            mem_mb = get_mem_mb_fastqc
        shell:
            f"""
                fastqc {{input.real:q}} -o {{config[outputs_files]:q}}Fastqc_out/{step}/
            """

######################## Function to create a rule for the multiqc on different steps  ###############################
def rule_multiqc(step, outputs_files, final_output):
    rule:
        name: f"N04_MultiQC_on_{step}"
        input:
            zip = expand(outputs_files + f"Fastqc_out/{step}/{{sample}}.{{read}}_fastqc.zip", sample=SAMPLES, read=READS),
            html = expand(outputs_files + f"Fastqc_out/{step}/{{sample}}.{{read}}_fastqc.html", sample=SAMPLES, read=READS)
        output:
            final_output + f"MultiQC/Quality_results_on_{step}.html"
        params:
            INDIR = outputs_files + f"Fastqc_out/{step}/",
            OUTDIR = final_output + "MultiQC/",
            OUTNAME = final_output + f"MultiQC/Quality_results_on_{step}"
        resources:
            mem_mb = get_mem_mb_multiqc
        message:
            f"Quality control with MultiQC on {step} data"
        shell:
            """
                multiqc {params.INDIR:q} -o {params.OUTDIR:q} -n {params.OUTNAME:q} --force
            """

######################## Function to create a rule for the multiqc on different steps  ###############################
def move_output(step, outputs_files, final_output):
    rule:
        name: f"N05_Move_Fastqc_out_after_{step}"
        input:
            final_output + f"MultiQC/Quality_results_on_{step}.html"
        output:
            expand(final_output + f"Fastqc_out/{step}/{{sample}}.{{read}}_fastqc.html", sample=SAMPLES, read=READS)
        params:
            inputs = expand(outputs_files + f"Fastqc_out/{step}/{{sample}}.{{read}}_fastqc.html", sample=SAMPLES, read=READS),
            outdir = final_output + f"Fastqc_out/{step}/",
        shell:
            """
                mv {params.inputs:q} {params.outdir:q}
            """

######################## Run the created functions on the raw and trimmed data  ###############################
for counter, step in enumerate(STEPS):
    rule_fastqc(step, raw_data_path, outputs_files)
    rule_multiqc(step, outputs_files, final_output)
    move_output(step, outputs_files, final_output)


######################## Map on the reference genome  ###############################
rule N06_Map_ref_genome:
    input:
        trimmed_R1 = rules.N02_FastP.output.fastp_R1,
        trimmed_R2 = rules.N02_FastP.output.fastp_R2,
        reference_genome_indexed = reference_genome + ".amb",
        ref_genome = reference_genome
    output:
        temp(outputs_files + "Mapped_genomes/{sample}.cram")
    threads: 10
    resources:
        partition="long",
        mem_mb = get_mem_mb_bwa
    message:
        "Mapping {wildcards.sample} on {NAME_GENOME}"
    shell:
        r"""
            mkdir -p {config[temp_path]}
            export TMPDIR="{config[temp_path]}" TMP="{config[temp_path]}" TEMP="{config[temp_path]}"
            bwa mem -M -t {threads} -R '@RG\tID:1\tSM:{wildcards.sample}\tPL:ILLUMINA\tLB:lib\tPU:transect' {input.ref_genome:q} {input.trimmed_R1:q} {input.trimmed_R2:q} | samtools view -C -T {input.ref_genome:q} > {output:q}
        """


######################## Collate the CRAM files  ###############################
rule N07_Collate_CRAM:
    input:
        rules.N06_Map_ref_genome.output
    output:
        temp(outputs_files + "Sorted_genomes/{sample}.0.cram")
    threads: 10
    resources:
        mem_mb = get_mem_mb_collate
    message:
        "Sorting {wildcards.sample}"
    shell:
        """
            samtools collate -@ {threads} {input:q}  -o {output:q} {config[temp_path]} --output-fmt CRAM 
        """


######################## Fixmate the CRAM files  ###############################
rule N08_Fixmate_CRAM:
    input:
        rules.N07_Collate_CRAM.output
    output:
        temp(outputs_files + "Sorted_genomes/{sample}.1.cram")
    threads: 10
    resources:
        mem_mb = get_mem_mb_fixmate
    message:
        "Sorting {wildcards.sample}"
    shell:
        """
            mkdir -p {config[temp_path]}
            export TMPDIR="{config[temp_path]}" TMP="{config[temp_path]}" TEMP="{config[temp_path]}"
            samtools fixmate -@ {threads} -m {input:q} -O CRAM {output:q}
        """


######################## Sort the CRAM files  ###############################
rule N09_Sort_CRAM:
    input:
        rules.N08_Fixmate_CRAM.output
    output:
        temp(outputs_files + "Sorted_genomes/{sample}.cram")
    threads: 10
    resources:
        mem_mb = get_mem_mb_sort
    message:
        "Sorting {wildcards.sample}"
    shell:
        """
            samtools sort -@ {threads} {input:q} -O CRAM -o {output:q} -T {config[temp_path]}
        """


######################## Mark the duplicates  ###############################
rule N10_Mark_duplicates:
    input:
        rules.N09_Sort_CRAM.output
    output:
        final_output + "Marked_duplicates/{sample}.cram"
    threads: 10
    resources:
        mem_mb = get_mem_mb_markdup
    message:
        "Marking duplicates for {wildcards.sample}"
    shell:
        """
            samtools markdup -@ {threads} -d 2500 {input:q} {output:q} -T {config[temp_path]} -O CRAM
        """


######################## Index the CRAM file and do some stats  ###############################
rule N11_Index_Flagstate:
    input:
        rules.N10_Mark_duplicates.output
    output:
        index = final_output + "Marked_duplicates/{sample}.cram.crai",
        flagstat = final_output + "Flagstat_reports/{sample}.flagstat"
    threads: 1
    message:
        "Indexing and making stats on {wildcards.sample}"
    shell:
        """
            samtools index -@ {threads} -b {input:q} > {output.index:q} 
            samtools flagstat -@ {threads} {input:q} > {output.flagstat:q}
        """


######################## Make a list of the CRAM files  ###############################
rule N12_Create_list_CRAM_files:
    input:
        real = expand(final_output + "Marked_duplicates/{sample}.cram", sample=SAMPLES),
        fake = expand(final_output + "Marked_duplicates/{sample}.cram.crai", sample=SAMPLES)
    output:
        temp(outputs_files + "Concatenation/List_cram_files.txt")
    shell:
        """
            LIST_DIR={config[final_output]}Marked_duplicates/*
            ls -d $LIST_DIR | grep -v ".crai" > {output:q}
        """


######################## Variant Calling  ###############################
rule N13_Compile_CRAM_files:
    input:
        ref_genome = reference_genome,
        list_cram_files = rules.N12_Create_list_CRAM_files.output,
        fake = expand(rules.N11_Index_Flagstate.output.index, sample=SAMPLES)
    output:
        final_output + "Full_VCF/VCF_File_{region}.vcf.gz"
    threads: 10
    resources:
        mem_mb = config["mem_mpileup"]
    params:
        region = expand("{region}", region=REGIONS)
    message:
        "VCF file preparation in region: {wildcards.region}"
    shell:
        """
            mkdir -p {config[temp_path]}
            export TMPDIR="{config[temp_path]}" TMP="{config[temp_path]}" TEMP="{config[temp_path]}"
            bcftools mpileup --threads {threads} -a FORMAT/AD,FORMAT/DP,FORMAT/SP,INFO/AD --fasta-ref {input.ref_genome:q} -b {input.list_cram_files:q} --regions {wildcards.region} | bcftools call --threads {threads} -m -Oz -o {output:q}
        """


######################## Filter on MAC of 1  ###############################
rule N14_MAC:
    input:
        rules.N13_Compile_CRAM_files.output
    output:
        temp(outputs_files + "Mac_data/VCF_File_{region}.vcf.gz")
    message:
        "Filtering Max Allele Count for {wildcards.region}"
    shell:
        """
            vcftools --gzvcf {input:q} --stdout --mac 1 --temp {config[temp_path]:q} --recode | gzip -c > {output:q}
        """


######################## Remove Indels and multiallelic sites  ###############################
rule N15_Remove_Indels:
    input:
        rules.N14_MAC.output
    output:
        temp(outputs_files + "Removed_indels/VCF_File_{region}.vcf.gz")
    threads: 10
    message:
        "Removing Indels and multiallelic sites for {wildcards.region}"
    shell:
        """
            mkdir -p {config[temp_path]}
            export TMPDIR="{config[temp_path]}" TMP="{config[temp_path]}" TEMP="{config[temp_path]}"
            bcftools filter -Ou --threads {threads} -g 5:indel,other {input:q} | bcftools view -Oz --threads {threads} -M 2 -m 2 -v snps > {output:q}
        """


######################## Filter on missing data rates  ###############################
rule N16_Filter_missing_rate:
    input:
        rules.N15_Remove_Indels.output
    output:
        temp(outputs_files + "Missing_data/VCF_File_{region}.vcf.gz")
    params:
        missing_rate = config["missing_rate]
    shell:
        """
            vcftools --gzvcf {input:q} --stdout --max-missing {params.missing_rate} --temp {config[temp_path]:q} --recode | gzip -c > {output:q}
        """


######################## SNP Count  ###############################
def make_rule_count_SNPs(step, outputs_files, final_output):
    rule:
        name: f"Count_SNPs_on_{step}_data"
        input:
            input_stats(step, outputs_files, final_output) + "VCF_File_{region}.vcf.gz"
        output:
            temp(outputs_files + f"{step}/Position_count_after_{step}_{{region}}.csv")
        shell:
            f"""
                NSNPs=$(echo "$(zcat {{input:q}} | grep -v '#' | wc -l) + 1" | bc)
                echo "{{wildcards.region}};$(echo "$NSNPs -1 " | bc)" >> {{output:q}}
            """

    rule:
        name: f"Concat_SNP_count_on_{step}_data"
        input:
            expand(outputs_files + f"{step}/Position_count_after_{step}_{{region}}.csv", region=REGIONS)
        output:
            final_output + f"{step}/Position_count.csv"
        shell:
            """
                cat {input:q} >> {output:q}
            """

######################## Concat vcf files  ###############################
def concat_vcf(step, outputs_files, final_output):
    rule:
        name: f"Concat_VCF_file_after_{step}"
        input:
            expand(input_stats(step, outputs_files, final_output) + "VCF_File_{region}.vcf.gz", region=REGIONS)
        output:
            temp_out = temp(outputs_files + f"{step}/VCF_File.vcf"),
            real = final_output + f"{step}/VCF_File.vcf.gz"
        shell:
            """
                zcat {input[0]:q} | grep "#" > {output.temp_out:q}
                zcat {input:q} | grep -v "#" >> {output.temp_out:q}
                gzip -c {output.temp_out:q} > {output.real:q}
            """

######################## Do Stats  ###############################
def stats_vcf(step, outputs_files, final_output):
    rule:
        name: f"Stats_on_{step}_data"
        input:
            input_stats(step, outputs_files, final_output) + "VCF_File_{region}.vcf.gz"
        output:
            site_qual = temp(outputs_files + f"{step}/Stats/site_qual_{{region}}_after_{step}.txt"),
            phred = temp(outputs_files + f"{step}/Stats/phred_qual_{{region}}_after_{step}.txt"),
            allel_freq = temp(outputs_files + f"{step}/Stats/allel_freq_{{region}}_after_{step}.txt"),
            depth = temp(outputs_files + f"{step}/Stats/tot_depth_{{region}}.ldepth.mean"),
            missing = temp(outputs_files + f"{step}/Stats/{{region}}.lmiss")
        params:
            OUTDIR_Stats = outputs_files + f"{step}/Stats/tot_depth_{{region}}",
            prefix_missing = outputs_files + f"{step}/Stats/{{region}}"
        shell:
            r"""
                mkdir -p {config[temp_path]}
                export TMPDIR="{config[temp_path]}" TMP="{config[temp_path]}" TEMP="{config[temp_path]}"

                # Call quality per site
                bcftools query -f "%CHROM\t%POS\t%QUAL\n" {input:q} > {output.site_qual:q}

                # Strand-bias P-value (Phread score)
                bcftools query -f "%CHROM\t%POS\t[%SP\t]\n" {input:q} | awk 'BEGIN{{OFS="\t"}}{{sum=0; for (i=3; i<=NF; i++) sum+=$i; sum/=NF; print $1,$2,sum}}' > {output.phred:q}

                # Depth per sample
                bcftools +fill-tags {input:q} -- -t AF | bcftools query -f "%CHROM\t%POS\t%AF\n" > {output.allel_freq:q}

                # Mean depth
                vcftools --gzvcf {input:q} --site-mean-depth --temp {config[temp_path]:q} --out {params.OUTDIR_Stats:q}

                # Missing data
                vcftools --gzvcf {input:q} --out {params.prefix_missing:q} --missing-site

            """

    rule:
        name: f"Concat_stats_on_{step}"
        input:
            site_qual = expand(outputs_files + f"{step}/Stats/site_qual_{{region}}_after_{step}.txt", region=REGIONS),
            phred = expand(outputs_files + f"{step}/Stats/phred_qual_{{region}}_after_{step}.txt", region=REGIONS),
            allel_freq = expand(outputs_files + f"{step}/Stats/allel_freq_{{region}}_after_{step}.txt", region=REGIONS),
            depth = expand(outputs_files + f"{step}/Stats/tot_depth_{{region}}.ldepth.mean", region=REGIONS),
            missing = expand(outputs_files + f"{step}/Stats/{{region}}.lmiss", region=REGIONS)
        output:
            site_qual = final_output + f"{step}/Stats/vcfstats.QUAL.txt", 
            phred = final_output + f"{step}/Stats/vcfstats.SP.txt", 
            allel_freq = final_output + f"{step}/Stats/vcfstats.AF.txt",
            depth = final_output + f"{step}/Stats/vcfstats.DP.txt",
            missing = final_output + f"{step}/Stats/vcfstats.lmiss"
        shell:
            """
                cat {input.site_qual:q} > {output.site_qual:q}
                cat {input.phred:q} > {output.phred:q}
                cat {input.allel_freq:q} > {output.allel_freq:q}
                cat {input.depth:q} | sort -n -k1,1 -k2,2 | uniq > {output.depth:q}
                cat {input.missing:q} | sort -n -k1,1 -k2,2 | uniq > {output.missing:q}
            """
    
    rule:
        name: f"Plot_graph_on_{step}"
        input:
            site_qual = final_output + f"{step}/Stats/vcfstats.QUAL.txt", 
            phred = final_output + f"{step}/Stats/vcfstats.SP.txt", 
            allel_freq = final_output + f"{step}/Stats/vcfstats.AF.txt",
            depth = final_output + f"{step}/Stats/vcfstats.DP.txt",
            missing = final_output + f"{step}/Stats/vcfstats.lmiss"
        output:
            final_output + f"{step}/Quality_distribution.png"
        params:
            input_path = final_output + f"{step}/",
            output_path = final_output + f"{step}/Quality_distribution"
        shell:
            """
                Rscript ./Graph_quality.r --input {params.input_path:q} --output {params.output_path:q}
            """
            

for step in LATE_STEPS:
    make_rule_count_SNPs(step, outputs_files, final_output)
    stats_vcf(step, outputs_files, final_output)
    if step != "Full_VCF":
        concat_vcf(step, outputs_files, final_output)
